{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will present how a simple AutoEncoder recommends the next item for the given basket. The dataset used in thise tutorial is available [here](https://www.kaggle.com/mittalvasu95/the-bread-basket). I chose this dataset for this tutorial because the dataset is small enough to implement our recommendation system quickly.\n",
    "\n",
    "### Before start\n",
    "- First of all, I really appreciate [@Aditya Mittal](https://www.kaggle.com/mittalvasu95) providing this dataset.\n",
    "- I am sorry for my poor English in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of df:  (20507, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction</th>\n",
       "      <th>Item</th>\n",
       "      <th>date_time</th>\n",
       "      <th>period_day</th>\n",
       "      <th>weekday_weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bread</td>\n",
       "      <td>30-10-2016 09:58</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>30-10-2016 10:05</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Scandinavian</td>\n",
       "      <td>30-10-2016 10:05</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hot chocolate</td>\n",
       "      <td>30-10-2016 10:07</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Jam</td>\n",
       "      <td>30-10-2016 10:07</td>\n",
       "      <td>morning</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction           Item         date_time period_day weekday_weekend\n",
       "0            1          Bread  30-10-2016 09:58    morning         weekend\n",
       "1            2   Scandinavian  30-10-2016 10:05    morning         weekend\n",
       "2            2   Scandinavian  30-10-2016 10:05    morning         weekend\n",
       "3            3  Hot chocolate  30-10-2016 10:07    morning         weekend\n",
       "4            3            Jam  30-10-2016 10:07    morning         weekend"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./bread basket.csv')\n",
    "print(\"The shape of df: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train, validation and test\n",
    "- There are 9,465 transactions\n",
    "- For this kind of data, we shouldn't split data randomly because we want to predict \"future\" transactions when \"past\" transactions are given.\n",
    "- Let's use the last 1,000 transactions as test data and last 1,000 transaction of remaining transactions as validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique transactions:  9465\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of unique transactions: \", df['Transaction'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of train transactions:  7465\n",
      "The number of validation transactions:  1000\n",
      "The number of test transactions:  1000\n"
     ]
    }
   ],
   "source": [
    "df['dataset'] = 'train'\n",
    "df.loc[df['Transaction'].isin(df['Transaction'].unique()[-1000:]), 'dataset'] = 'test'\n",
    "df.loc[df['Transaction'].isin(df['Transaction'].unique()[-2000:-1000]), 'dataset'] = 'valid'\n",
    "\n",
    "print(\"The number of train transactions: \", df.loc[df['dataset'] == 'train', 'Transaction'].nunique())\n",
    "print(\"The number of validation transactions: \", df.loc[df['dataset'] == 'valid', 'Transaction'].nunique())\n",
    "print(\"The number of test transactions: \", df.loc[df['dataset'] == 'test', 'Transaction'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply label encoding to `Item`\n",
    "- There are many ways to implement label-encoding. Among them, I use `pandas.Categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_encoder = pd.Categorical(df['Item'])\n",
    "label_encoder = {k: v for v, k in enumerate(label_encoder.categories)}\n",
    "df['Item_encoded'] = df['Item'].apply(lambda x: label_encoder[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (optional) It is helpful to print `label_encoder` for understanding\n",
    "\n",
    "~~~python\n",
    "print(label_encoder)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create `torch.nn.Dataset`\n",
    "- Honestly, it is not necessary to make `torch.nn.Dataset` for small dataset. (But, I'm sure it is worth using it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasketDataset(Dataset):\n",
    "    def __init__(self, df, dim_input, mode):\n",
    "        super(BasketDataset, self).__init__()\n",
    "        self.df = df\n",
    "        self.dim_input = dim_input\n",
    "        self.mode = mode\n",
    "        self.indices = df['Transaction'].unique()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        transaction_id = self.indices[index]\n",
    "        items = df.loc[df['Transaction'] == transaction_id, 'Item_encoded'].values\n",
    "        \n",
    "        X = torch.zeros(self.dim_input, dtype=torch.float32)\n",
    "        y = torch.zeros(self.dim_input, dtype=torch.float32)\n",
    "        X[items] = 1\n",
    "        y[items] = 1\n",
    "        \n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (optional) Print `X` and `y` generated by BasketDataset\n",
    "\n",
    "~~~python\n",
    "dataset = BasketDataset(df=df[df['dataset'] == 'train'],\n",
    "                        dim=94,\n",
    "                        mode='train')\n",
    "\n",
    "X, y = dataset[0]\n",
    "print('X: ', X)\n",
    "print('y: ', y)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "- I use a very simple AutoEncoder, that is, it has only one hidden layer.\n",
    "- Dropout is used to only Encoder.\n",
    "- Activation functions of Encoder and Decoder are sigmoid.\n",
    "- It sounds like very poor model, but it is very powerful !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_input, dim_latent, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.latent_layer = nn.Linear(dim_input, dim_latent)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.latent_layer(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dim_output, dim_latent):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.output_layer = nn.Linear(dim_latent, dim_output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.output_layer(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, dim_input, dim_latent, dropout):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = Encoder(dim_input, dim_latent, dropout)\n",
    "        self.decoder = Decoder(dim_input, dim_latent)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (optional) To the best of my knowledge, the original AutoEncoder shares weights of encoder and decoder, which called `Tied AutoEncoder`. Build  `TiedAutoEncoder` and compare it's performance with AutoEncoder (Honestly, I don't know how to implement `TiedAutoEncoder`T_T)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitter\n",
    "- Next, we will make a class that trains, evaluates, and predicts for given model and data loaders.\n",
    "- Let's make a helper class storing and averaging the losses first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.value = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, value, n):\n",
    "        self.value = value\n",
    "        self.sum += value * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter:\n",
    "    def __init__(self, model, lr, n_epochs):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.criterion = torch.nn.BCELoss()\n",
    "        \n",
    "        self.best_summary_loss = 10 ** 5\n",
    "        \n",
    "    def fit(self, train_loader, valid_loader):\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Train\n",
    "            t = time.time()\n",
    "            summary_loss = self.train_one_epoch(train_loader)\n",
    "            print(\n",
    "                f'\\rEpoch:{epoch + 1}/{self.n_epochs} | ' +\n",
    "                f'Train loss: {summary_loss.avg:.7f} | ' +\n",
    "                f'Elapsed time: {time.time() - t:.3f} |'\n",
    "            )\n",
    "            \n",
    "            # Evaluation\n",
    "            t = time.time()\n",
    "            summary_loss = self.evaluate(valid_loader)\n",
    "            print(\n",
    "                f'\\rEpoch:{epoch + 1}/{self.n_epochs} | ' +\n",
    "                f'Validation loss: {summary_loss.avg:.7f} | ' +\n",
    "                f'Elapsed time: {time.time() - t:.3f}'\n",
    "            )\n",
    "        # End for (n_epochs)\n",
    "        \n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        \n",
    "        for step, (X, y) in enumerate(train_loader):\n",
    "            print(\n",
    "                f'Train step: {step + 1}/{len(train_loader)} | ' +\n",
    "                f'Summary loss: {summary_loss.avg:.7f} | ' +\n",
    "                f'Time: {time.time() - t:.3f} |', end='\\r'\n",
    "            )\n",
    "            X = X.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            batch_size = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(X)\n",
    "            loss = self.criterion(output, y)\n",
    "            loss.backward()\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "            self.optimizer.step()\n",
    "        # End for (one epoch)\n",
    "        return summary_loss\n",
    "        \n",
    "    def evaluate(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(valid_loader):\n",
    "                print(\n",
    "                    f'Valid step: {step + 1}/{len(valid_loader)} | ' +\n",
    "                    f'Summary loss: {summary_loss.avg:.7f} | ' + \n",
    "                    f'Time: {time.time() - t:.3f} |', end='\\r'\n",
    "                )\n",
    "\n",
    "                X = X.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                batch_size = X.shape[0]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(X)\n",
    "                loss = self.criterion(output, y)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "            # End for (One epoch)\n",
    "        # End with (validataion)\n",
    "        return summary_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (optional, but necessary) You will see that our losses are very small. Why? There are many zeros in our target `y`, so that if our model predicts all values as 0 the average of losses go to 0. We can alleviate this problem by providing different weights to 0 and 1. To this end, we should make our own loss function.\n",
    "\n",
    "~~~python\n",
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "    '''\n",
    "    code from https://discuss.pytorch.org/t/solved-class-weight-for-bceloss/3114/2\n",
    "    '''    \n",
    "    if weights is not None:\n",
    "        assert len(weights) == 2\n",
    "        \n",
    "        loss = weights[1] * (target * torch.log(output)) + \\\n",
    "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "        \n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "\n",
    "    return torch.neg(torch.mean(loss))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train our model\n",
    "- Define `BasketDataset` and pass it through `torch.nn.DataLoader`\n",
    "- Define our `AutoEncoder` model\n",
    "- Combine and train our model and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_INPUT = 94 # The number of unique items\n",
    "DIM_LATENT = 64 # The number of nodes of the latent layer\n",
    "BATCH_SIZE = 16\n",
    "DROPOUT = 0.1\n",
    "LR = 0.001\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BasketDataset(df=df[df['dataset'] == 'train'],\n",
    "                              dim_input=DIM_INPUT,\n",
    "                              mode='train')\n",
    "valid_dataset = BasketDataset(df=df[df['dataset'] == 'valid'],\n",
    "                              dim_input=DIM_INPUT,\n",
    "                              mode='train')\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder(DIM_INPUT, DIM_LATENT, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = Fitter(model, LR, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/10 | Train loss: 0.1284798 | Elapsed time: 3.735 |3 |\n",
      "Epoch:1/10 | Validation loss: 0.0714454 | Elapsed time: 0.380\n",
      "Epoch:2/10 | Train loss: 0.0666606 | Elapsed time: 3.408 |6 |\n",
      "Epoch:2/10 | Validation loss: 0.0658097 | Elapsed time: 0.414\n",
      "Epoch:3/10 | Train loss: 0.0605446 | Elapsed time: 3.435 |3 |\n",
      "Epoch:3/10 | Validation loss: 0.0582660 | Elapsed time: 0.385\n",
      "Epoch:4/10 | Train loss: 0.0511943 | Elapsed time: 3.407 |4 |\n",
      "Epoch:4/10 | Validation loss: 0.0480558 | Elapsed time: 0.397\n",
      "Epoch:5/10 | Train loss: 0.0414551 | Elapsed time: 3.319 |6 |\n",
      "Epoch:5/10 | Validation loss: 0.0391147 | Elapsed time: 0.408\n",
      "Epoch:6/10 | Train loss: 0.0333258 | Elapsed time: 3.456 |4 |\n",
      "Epoch:6/10 | Validation loss: 0.0321758 | Elapsed time: 0.386\n",
      "Epoch:7/10 | Train loss: 0.0268864 | Elapsed time: 3.486 |4 |\n",
      "Epoch:7/10 | Validation loss: 0.0265547 | Elapsed time: 0.399\n",
      "Epoch:8/10 | Train loss: 0.0219704 | Elapsed time: 3.425 |3 |\n",
      "Epoch:8/10 | Validation loss: 0.0221803 | Elapsed time: 0.400\n",
      "Epoch:9/10 | Train loss: 0.0182879 | Elapsed time: 3.403 |1 |\n",
      "Epoch:9/10 | Validation loss: 0.0188838 | Elapsed time: 0.410\n",
      "Epoch:10/10 | Train loss: 0.0154962 | Elapsed time: 3.452 | |\n",
      "Epoch:10/10 | Validation loss: 0.0162873 | Elapsed time: 0.392\n"
     ]
    }
   ],
   "source": [
    "fitter.fit(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend items for given basket\n",
    "- I will show you some good results.\n",
    "- Note that actually our model is not good because of the following:\n",
    "    - Since almost all customers buy only 1~2 items, then our model cannot learn latent space enough.\n",
    "    - It tends to recommend popular items such as `bread` or `coffee` (due to data imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {v: k for k, v in label_encoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = BasketDataset(df=df[df['dataset'] == 'test'],\n",
    "                              dim_input=DIM_INPUT,\n",
    "                              mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look the 707th transaction in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bread', 'Cake', 'Coffee', 'Extra Salami or Feta', 'Juice', 'Salad', 'Spanish Brunch']\n"
     ]
    }
   ],
   "source": [
    "sample_id = 707\n",
    "\n",
    "X, y = test_dataset[sample_id]\n",
    "\n",
    "print([label_decoder[item.item()] for item in torch.where(X == 1)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's assume the customer picks from `Bread` to `Salad` only. Then our model can recommend `Spanish Brunch`?\n",
    "- To this end, create `X_denoised` basket that has no `Spanish Brunch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bread', 'Cake', 'Coffee', 'Extra Salami or Feta', 'Juice', 'Salad']\n"
     ]
    }
   ],
   "source": [
    "X_denoised = X.clone()\n",
    "X_denoised[torch.where(X == 1)[0][-1]] = 0\n",
    "\n",
    "basket = [label_decoder[item.item()] for item in torch.where(X_denoised == 1)[0]]\n",
    "print(basket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Among the model's output, `Spanish Brunch` has the maximum logit value, except for the items tht are already in the basket.\n",
    "- That is, our model recommends `Spanish Brunch` to the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Spanish Brunch', 'Jammie Dodgers', 'Frittata', 'Scone', 'Sandwich', 'Muffin']\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "output = model(X_denoised).detach().numpy()\n",
    "TopK = np.argsort(-output)[:10]\n",
    "\n",
    "print([label_decoder[item] for item in TopK if label_decoder[item] not in basket])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 700th transaction in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coffee', 'Drinking chocolate spoons ', 'Juice', 'Mineral water', 'Salad', 'Sandwich']\n"
     ]
    }
   ],
   "source": [
    "sample_id = 700\n",
    "\n",
    "X, y = test_dataset[sample_id]\n",
    "print([label_decoder[item.item()] for item in torch.where(X == 1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coffee', 'Drinking chocolate spoons ', 'Juice', 'Mineral water', 'Salad']\n"
     ]
    }
   ],
   "source": [
    "X_denoised = X.clone()\n",
    "X_denoised[torch.where(X == 1)[0][-1]] = 0\n",
    "\n",
    "basket = [label_decoder[item.item()] for item in torch.where(X_denoised == 1)[0]]\n",
    "print(basket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sandwich', 'Spanish Brunch', 'Scone', 'Soup', 'Alfajores', 'Chicken Stew', 'Hearty & Seasonal']\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "output = model(X_denoised).detach().numpy()\n",
    "TopK = np.argsort(-output)[:10]\n",
    "\n",
    "print([label_decoder[item] for item in TopK if label_decoder[item] not in basket])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "- Visualize the latent space of items. Are they clustered properly? \n",
    "- Try the Denoising AutoEncoder that masks some items of an input, but still have to reconsturct the original input. For example, let's assumt an input $X$ has items `['Coffee', 'Drinking chocolate spoons ', 'Juice', 'Mineral water', 'Salad', 'Sandwich']`. The input and output of AutoEncoder are $X$ itself. However, the Denoising AutoEncoder has to reconstruct $X$ for the given denoised input $X_{\\text{denoised}}$ whose some items are masked, for example $X_{\\text{denoised}}$=`['Coffee', 'Juice', 'Salad', 'Sandwich']`. Denoising AutoEncoder provides more robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
